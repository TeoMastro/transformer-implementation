{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "000fc1af-8dc3-407a-8fc6-6df3e2d2bbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (4.36.2)\n",
      "Requirement already satisfied: datasets in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (2.16.0)\n",
      "Requirement already satisfied: evaluate in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: sacrebleu in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from transformers) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from datasets) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from datasets) (2.1.4)\n",
      "Requirement already satisfied: xxhash in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from datasets) (3.9.1)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: portalocker in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from sacrebleu) (2.8.2)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from sacrebleu) (4.9.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from portalocker->sacrebleu) (305.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\teo\\anaconda3\\envs\\py310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers datasets evaluate sacrebleu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637acde7-e550-40c2-81f4-b59c229a05e6",
   "metadata": {},
   "source": [
    "# Load a sample dataset and split to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8fb2cb0e-82b3-4d99-9c98-289b27bf1b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "books = load_dataset(\"opus_books\", \"en-fr\")\n",
    "books = books[\"train\"].train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be2ec24-6535-4885-a81b-6806c4ce11c9",
   "metadata": {},
   "source": [
    "# An example of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8f25df30-222d-4845-909c-64af46bb493a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '108121',\n",
       " 'translation': {'en': 'It might be thought that this was Captain Speedy.',\n",
       "  'fr': 'Certes, on doit croire que cet homme était le capitaine Speedy !'}}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f539bab-e3a9-402e-a997-9c960dcc5725",
   "metadata": {},
   "source": [
    "# Import a tokenizer to process language pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0534457a-c896-4539-be30-ae19a8303e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24d5c25-8843-48e9-af8f-31707fd61f05",
   "metadata": {},
   "source": [
    "# Preprocess language pairs by tokenizing inputs and targets separately\n",
    "(since you can’t tokenize French text with a tokenizer pretrained on an English vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "34b3cb78-df06-488e-9e73-7e2479f1cb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_lang = \"en\"\n",
    "target_lang = \"fr\"\n",
    "prefix = \"translate English to French: \"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + example[source_lang] for example in examples[\"translation\"]]\n",
    "    targets = [example[target_lang] for example in examples[\"translation\"]]\n",
    "    model_inputs = tokenizer(inputs, text_target=targets, max_length=128, truncation=True)\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0786645f-64ab-4ca7-9f51-9ed03fe721d3",
   "metadata": {},
   "source": [
    "# Apply the preprocess function to the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e6a6e219-3735-411d-ab15-6e92d184368e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 101668/101668 [00:07<00:00, 12851.16 examples/s]\n",
      "Map: 100%|██████████| 25417/25417 [00:02<00:00, 12551.21 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_books = books.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbbfe40-dc49-4c66-864a-021861e356a9",
   "metadata": {},
   "source": [
    "# Create batches of dict-like objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bc9b911a-9a9b-4c7d-8f52-9b1606ead286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b760de15-af3d-46a3-850e-ef5cc4715b63",
   "metadata": {},
   "source": [
    "# Import a metric for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6908e6cd-2f1e-47fa-ab5c-00b5b65bfe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02ada2d-cbe7-40ce-adda-9543623025f1",
   "metadata": {},
   "source": [
    "# Create a function that passes your predictions and labels to compute to calculate the SacreBLEU score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8f68a06f-2175-4985-b816-84f60786d84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c24fda8-9c7b-4de7-8c9d-81e71ec0a21e",
   "metadata": {},
   "source": [
    "# Transformer finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ea83d75f-49a1-4a6f-87dc-1b8e40213946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamWeightDecay\n",
    "\n",
    "optimizer = AdamWeightDecay(learning_rate=2e-5, weight_decay_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "412864b5-1420-4cc5-991c-94167bdb52b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForSeq2SeqLM\n",
    "\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5619fb7b-f555-4c6b-a8ae-67167f081838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "tf_train_set = model.prepare_tf_dataset(\n",
    "    tokenized_books[\"train\"],\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "tf_test_set = model.prepare_tf_dataset(\n",
    "    tokenized_books[\"test\"],\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60058168-f529-4e91-a06c-a3875b86f73b",
   "metadata": {},
   "source": [
    "# Compile and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b88fbf51-34f7-4e14-9c27-ca44e9e03569",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamWeightDecay(learning_rate=2e-5, weight_decay_rate=0.01)\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2a92437c-b5cd-4da0-b27e-a2e39346c7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e8053deb-b846-4c19-85c1-3d1b3d940f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6354/6354 [==============================] - 1319s 206ms/step - loss: 1.9138 - val_loss: 1.6115\n"
     ]
    }
   ],
   "source": [
    "model.fit(x=tf_train_set, validation_data=tf_test_set, epochs=1)\n",
    "model.save_pretrained(\"tf_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "628aaf80-ad75-4ccb-ae57-f3cc248066da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at tf_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"translate English to French: Legumes share resources with nitrogen-fixing bacteria.\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(\"tf_model/\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "01ce8dc7-b3e5-4506-9b3d-4fec95e0640b",
   "metadata": {},
   "source": [
    "# Generate the translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "49572d72-508f-4a71-a21e-49e4bab23b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[    0   622     3    40   154  1744  2687 16762    29    17   110 17126\n",
      "    393   110     3  9305  2229  2593  2210 11488     7     3    26    31\n",
      "  17694    17    15     5     1]], shape=(1, 29), dtype=int32)\n",
      "Les légumes partagent les ressources avec les bactéries fixatrices d'azote.\n"
     ]
    }
   ],
   "source": [
    "tokenized = tokenizer([input_text], return_tensors='np')\n",
    "out = model.generate(**tokenized, max_length=128)\n",
    "print(out)\n",
    "\n",
    "with tokenizer.as_target_tokenizer():\n",
    "    print(tokenizer.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3325a30b-670f-402d-a010-137897f781ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
